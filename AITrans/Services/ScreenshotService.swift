//
//  ScreenshotService.swift
//  AITrans
//
//  Created by LEO on 14/9/2568 BE.
//

import AppKit
import Vision
import CoreGraphics

/// ç»Ÿä¸€çš„æˆªå›¾æœåŠ¡ï¼Œç®¡ç†æ‰€æœ‰æˆªå›¾æ“ä½œ
class ScreenshotService: ObservableObject {
    static let shared: ScreenshotService = ScreenshotService()
    
    private init() {}
    
    /// æˆªå›¾æ¥æºæžšä¸¾
    enum ScreenshotSource: String {
        case statusBar = "StatusBar"
        case floatingQuickIcon = "FloatingQuickIcon"
        case floatingResultWindow = "FloatingResultWindow"
        case keyboardShortcut = "KeyboardShortcut"
    }
    
    /// å¼€å§‹æˆªå›¾æ“ä½œ
    /// - Parameter source: æˆªå›¾æ¥æº
    func startScreenshotCapture(source: ScreenshotSource) {
        print("ðŸŸ¢ ScreenshotService: å¼€å§‹æˆªå›¾æ“ä½œï¼Œæ¥æº: \(source.rawValue)")
        
        // æ£€æŸ¥æƒé™
        guard checkScreenRecordingPermission() else {
            print("ðŸ”´ ScreenshotService: å±å¹•å½•åˆ¶æƒé™æ£€æŸ¥å¤±è´¥")
            print("ðŸ”´ ScreenshotService: è¯·æ£€æŸ¥ç³»ç»Ÿåå¥½è®¾ç½® > å®‰å…¨æ€§ä¸Žéšç§ > å±å¹•å½•åˆ¶æƒé™")
            showPermissionAlert()
            return
        }
        print("ðŸŸ¢ ScreenshotService: å±å¹•å½•åˆ¶æƒé™æ£€æŸ¥é€šè¿‡")
        
        // æˆªå›¾æ—¶åªéšè—AIé¢æ¿ï¼Œä¿æŒæµ®åŠ¨çª—å£å¯è§
        print("ScreenshotService: æˆªå›¾æ—¶éšè—AIé¢æ¿ï¼Œä¿æŒçª—å£å¯è§")
        if let currentWindow = FloatingResultWindowManager.shared.getCurrentWindow() {
            currentWindow.hideAIDetailExplanationPanel()
        }
        
        // ä½¿ç”¨screencaptureå‘½ä»¤æˆªå›¾
        let task = Process()
        task.launchPath = "/usr/sbin/screencapture"
        task.arguments = ["-i", "-c"] // -i äº¤äº’å¼é€‰æ‹©åŒºåŸŸï¼Œ-c å¤åˆ¶åˆ°å‰ªè´´æ¿
        
        let pipe = Pipe()
        task.standardError = pipe // screencaptureçš„è¾“å‡ºé€šå¸¸åœ¨stderr
        
        task.terminationHandler = { process in
            print("ScreenshotService: screencaptureè¿›ç¨‹ç»“æŸï¼Œé€€å‡ºç : \(process.terminationStatus)")
            if process.terminationStatus == 0 {
                // æˆªå›¾æˆåŠŸï¼Œä»Žå‰ªè´´æ¿èŽ·å–å›¾ç‰‡
                DispatchQueue.main.async {
                    print("ScreenshotService: å°è¯•ä»Žå‰ªè´´æ¿èŽ·å–å›¾ç‰‡...")
                    if let clipboard = NSPasteboard.general.data(forType: .tiff),
                       let image = NSImage(data: clipboard) {
                        print("ScreenshotService: æˆåŠŸèŽ·å–å‰ªè´´æ¿å›¾ç‰‡ï¼Œå¼€å§‹OCRè¯†åˆ«")
                        self.performOCR(on: image, source: source)
                    } else {
                        print("ScreenshotService: å‰ªè´´æ¿ä¸­æ²¡æœ‰å›¾ç‰‡")
                    }
                }
            } else {
                print("ScreenshotService: æˆªå›¾å¤±è´¥ï¼Œé€€å‡ºç : \(process.terminationStatus)")
                // å¤„ç†ç”¨æˆ·å–æ¶ˆæˆªå›¾çš„æƒ…å†µ
                if process.terminationReason == .exit && process.terminationStatus == 1 {
                    print("ScreenshotService: ç”¨æˆ·å–æ¶ˆäº†æˆªå›¾æ“ä½œã€‚")
                }
            }
        }
        
        task.launch()
    }
    
    /// æ£€æŸ¥å±å¹•å½•åˆ¶æƒé™
    private func checkScreenRecordingPermission() -> Bool {
        let screenCapturePermission = CGPreflightScreenCaptureAccess()
        return screenCapturePermission
    }
    
    /// æ˜¾ç¤ºæƒé™æç¤ºå¯¹è¯æ¡†
    private func showPermissionAlert() {
        DispatchQueue.main.async {
            let alert = NSAlert()
            alert.messageText = LocalizationManager.localized("screen_recording_permission_required")
            alert.informativeText = LocalizationManager.localized("screen_recording_permission_description")
            alert.addButton(withTitle: LocalizationManager.localized("open_system_preferences"))
            alert.addButton(withTitle: LocalizationManager.localized("cancel"))
            
            let response = alert.runModal()
            if response == .alertFirstButtonReturn {
                // æ‰“å¼€ç³»ç»Ÿåå¥½è®¾ç½®
                if let url = URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture") {
                    NSWorkspace.shared.open(url)
                }
            }
        }
    }
    
    /// æ‰§è¡ŒOCRè¯†åˆ«
    /// - Parameters:
    ///   - image: è¦è¯†åˆ«çš„å›¾ç‰‡
    ///   - source: æˆªå›¾æ¥æº
    private func performOCR(on image: NSImage, source: ScreenshotSource) {
        print("ScreenshotService: å¼€å§‹OCRå¤„ç†ï¼Œæ¥æº: \(source.rawValue)")
        
        guard let cgImage = image.cgImage(forProposedRect: nil, context: nil, hints: nil) else {
            print("ScreenshotService: æ— æ³•å°†NSImageè½¬æ¢ä¸ºCGImage")
            return
        }
        
        print("ScreenshotService: æˆåŠŸè½¬æ¢ä¸ºCGImageï¼Œå¼€å§‹Visionè¯†åˆ«")
        
        let request = VNRecognizeTextRequest { request, error in
            if let error = error {
                print("ScreenshotService: OCRè¯†åˆ«é”™è¯¯: \(error.localizedDescription)")
                return
            }
            
            guard let observations = request.results as? [VNRecognizedTextObservation] else {
                print("ScreenshotService: OCRè¯†åˆ«ç»“æžœä¸ºç©º")
                return
            }
            
            let recognizedStrings = observations.compactMap { observation in
                observation.topCandidates(1).first?.string
            }
            
            // åŽŸå§‹å¤šè¡Œæ–‡æœ¬
            let multiLineText = recognizedStrings.joined(separator: "\n")
            print("ScreenshotService: OCRè¯†åˆ«ç»“æžœ(å¤šè¡Œ): \(multiLineText)")
            
            // å°†å¤šè¡Œæ–‡æœ¬è½¬æ¢ä¸ºä¸€è¡Œï¼Œç”¨ç©ºæ ¼è¿žæŽ¥
            let singleLineText = self.convertToSingleLine(multiLineText)
            print("ScreenshotService: OCRè¯†åˆ«ç»“æžœ(ä¸€è¡Œ): \(singleLineText)")
            
            DispatchQueue.main.async {
                // æ£€æŸ¥æ˜¯å¦è¯†åˆ«å‡ºæ–‡æœ¬
                if singleLineText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                    // æ²¡æœ‰è¯†åˆ«å‡ºæ–‡æœ¬ï¼Œæ˜¾ç¤ºæé†’
                    self.showFloatingResultWindow(text: "âš ï¸ \(LocalizationManager.localized("no_text_detected"))")
                } else {
                    // å°†è¯†åˆ«çš„æ–‡å­—å¤åˆ¶åˆ°å‰ªè´´æ¿
                    self.copyTextToClipboard(singleLineText)
                    
                    // æ˜¾ç¤ºå¼¹å‡ºçª—å£
                    self.showFloatingResultWindow(text: singleLineText)
                }
            }
        }
        
        // è®¾ç½®è¯†åˆ«å‚æ•°
        request.recognitionLevel = .accurate  // é«˜ç²¾åº¦è¯†åˆ«
        request.usesLanguageCorrection = true // å¯ç”¨è¯­è¨€çº æ­£
        
        // æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æºè¯­è¨€è®¾ç½®OCRè¯†åˆ«è¯­è¨€
        if let sourceLanguageCode = getCurrentSourceLanguageCode() {
            // ç”¨æˆ·æŒ‡å®šäº†å…·ä½“è¯­è¨€ï¼Œä½¿ç”¨è¯¥è¯­è¨€è¿›è¡Œè¯†åˆ«
            request.automaticallyDetectsLanguage = false
            request.recognitionLanguages = [mapToOCRLanguageCode(sourceLanguageCode)]
            print("ScreenshotService: ä½¿ç”¨æŒ‡å®šè¯­è¨€è¿›è¡ŒOCRè¯†åˆ«: \(sourceLanguageCode) -> \(mapToOCRLanguageCode(sourceLanguageCode))")
        } else {
            // ç”¨æˆ·æœªæŒ‡å®šè¯­è¨€ï¼Œä½¿ç”¨è‡ªåŠ¨æ£€æµ‹
            request.automaticallyDetectsLanguage = true
            print("ScreenshotService: ä½¿ç”¨è‡ªåŠ¨è¯­è¨€æ£€æµ‹è¿›è¡ŒOCRè¯†åˆ«")
        }
        
        // æ‰§è¡Œè¯†åˆ«
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        do {
            try handler.perform([request])
        } catch {
            print("ScreenshotService: OCRè¯†åˆ«æ‰§è¡Œå¤±è´¥: \(error.localizedDescription)")
        }
    }
    
    // MARK: - Clipboard Operations
    
    private func copyTextToClipboard(_ text: String) {
        let pasteboard = NSPasteboard.general
        pasteboard.clearContents()
        pasteboard.setString(text, forType: .string)
        print("ðŸ“‹ ScreenshotService: å·²å°†è¯†åˆ«æ–‡å­—å¤åˆ¶åˆ°å‰ªè´´æ¿: \(text)")
    }
    
    /// æ˜¾ç¤ºæµ®åŠ¨ç»“æžœçª—å£
    /// - Parameter text: è¦æ˜¾ç¤ºçš„æ–‡æœ¬
    private func showFloatingResultWindow(text: String) {
        // èŽ·å–å½“å‰é¼ æ ‡ä½ç½®
        let mouseLocation = NSEvent.mouseLocation
        print("ScreenshotService: å‡†å¤‡æ˜¾ç¤ºç»“æžœçª—å£ï¼Œæ–‡æœ¬: \(text), é¼ æ ‡ä½ç½®: \(mouseLocation)")
        
        // é€šè¿‡FloatingResultWindowManageræ˜¾ç¤ºç»“æžœ
        FloatingResultWindowManager.shared.showResultWindow(text: text)
    }
    
    /// å°†å¤šè¡Œæ–‡æœ¬è½¬æ¢ä¸ºå•è¡Œæ–‡æœ¬
    /// - Parameter multiLineText: å¤šè¡Œæ–‡æœ¬
    /// - Returns: å•è¡Œæ–‡æœ¬
    private func convertToSingleLine(_ multiLineText: String) -> String {
        // å°†æ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼ï¼Œå¹¶æ¸…ç†å¤šä½™çš„ç©ºæ ¼
        let singleLine = multiLineText
            .replacingOccurrences(of: "\n", with: " ")
            .replacingOccurrences(of: "\r", with: " ")
            .replacingOccurrences(of: "\t", with: " ")
            .replacingOccurrences(of: "\\s+", with: " ", options: .regularExpression)
            .trimmingCharacters(in: .whitespacesAndNewlines)
        
        return singleLine
    }
    
    /// èŽ·å–å½“å‰æºè¯­è¨€ä»£ç 
    /// - Returns: æºè¯­è¨€ä»£ç 
    private func getCurrentSourceLanguageCode() -> String? {
        return UserDefaults.standard.string(forKey: "AITransSourceLanguageCode")
    }
    
    /// å°†ç¿»è¯‘è¯­è¨€ä»£ç æ˜ å°„ä¸ºOCRè¯­è¨€ä»£ç 
    /// - Parameter translationCode: ç¿»è¯‘è¯­è¨€ä»£ç 
    /// - Returns: OCRè¯­è¨€ä»£ç 
    private func mapToOCRLanguageCode(_ translationCode: String) -> String {
        let mapping: [String: String] = [
            "en": "en-US",
            "zh": "zh-Hans",
            "ja": "ja-JP",
            "ko": "ko-KR",
            "fr": "fr-FR",
            "de": "de-DE",
            "es": "es-ES",
            "it": "it-IT",
            "pt": "pt-BR",
            "ru": "ru-RU",
            "ar": "ar-SA",
            "hi": "hi-IN",
            "th": "th-TH",
            "vi": "vi-VN"
        ]
        return mapping[translationCode] ?? "en-US"
    }
}
